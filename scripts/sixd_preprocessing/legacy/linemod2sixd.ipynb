{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append('../..')\n",
    "#sys.path.append(os.path.join(os.path.dirname(os.path.dirname(__file__))))\n",
    "\n",
    "import shutil\n",
    "import json\n",
    "# from lib.rigidpose.sixd_toolkit import pysixd\n",
    "from lib.rigidpose.sixd_toolkit.pysixd import inout\n",
    "from model_conversion_occl2hint import model_conversion_meta\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "# from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join('/home/lucas/object-pose-estimation/local_conf.json')) as f:\n",
    "    local_conf = json.load(f)\n",
    "\n",
    "with open('/home/lucas/object-pose-estimation/meta.json') as f:\n",
    "    meta = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_pose(pose_path, parse_extent=False):\n",
    "    \"\"\"\n",
    "    Parses text file for annotated pose, which is returned.\n",
    "    \"\"\"\n",
    "    def read_array(lines):\n",
    "        return np.array([list(map(float, line.split())) for line in lines])\n",
    "    if not os.path.exists(pose_path):\n",
    "        return None\n",
    "    with open(pose_path) as f:\n",
    "        lines = f.readlines()\n",
    "\n",
    "    D = np.diag([1,-1,-1]);\n",
    "\n",
    "    ret = {}\n",
    "\n",
    "    i = 0\n",
    "    while i < len(lines):\n",
    "        line = lines[i].strip()\n",
    "        i += 1\n",
    "        if line == 'rotation:':\n",
    "            # Transform camera coordinate system for complying conventions\n",
    "            ret['R'] = np.dot(D, read_array(lines[i:i+3]))\n",
    "            i += 3\n",
    "            continue\n",
    "        elif line == 'center:':\n",
    "            # Transform camera coordinate system for complying conventions\n",
    "            ret['t'] = np.dot(D, read_array([lines[i]]).T)\n",
    "            if not parse_extent:\n",
    "                break\n",
    "            i += 1\n",
    "            continue\n",
    "        elif line == 'extent:':\n",
    "            ret['extent'] = read_array([lines[i]]).T\n",
    "            break\n",
    "    else:\n",
    "        # File contains no pose annotation\n",
    "        return None\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pose_paths(seq, frame_idx, pose_annos_path, considered_objs=None):\n",
    "    \"\"\"\n",
    "    Returns a dict of paths for the objects annotated in the corresponding sequence / frame.\n",
    "    \"\"\"\n",
    "    if considered_objs is None:\n",
    "        considered_objs = sorted(meta['objects'].keys())\n",
    "    pose_paths = {}\n",
    "    for obj in considered_objs:\n",
    "        if meta['objects'][obj]['mesh_id'] is None:\n",
    "            continue\n",
    "        pose_path = os.path.join(pose_annos_path, seq, '{:03}'.format(meta['objects'][obj]['mesh_id']), 'info', 'info_{:05}.txt'.format(frame_idx))\n",
    "        if not os.path.exists(pose_path):\n",
    "            continue\n",
    "        pose = parse_pose(pose_path)\n",
    "        if pose is not None:\n",
    "            pose_paths[obj] = pose_path\n",
    "    return pose_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seg2pixelcount(seg, label):\n",
    "    silhouette_pixels = np.argwhere(seg == label)\n",
    "    return silhouette_pixels.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seg2bb(seg, label):\n",
    "    silhouette_pixels = np.argwhere(seg == label)\n",
    "    if silhouette_pixels.shape[0] == 0:\n",
    "        # Some instances seem to have pose annotation despite not being visible... 100% occluded by other objects?\n",
    "        return None\n",
    "    xmin, ymin = np.min(silhouette_pixels, axis=0)\n",
    "    xmax, ymax = np.max(silhouette_pixels, axis=0)\n",
    "#     TODO: Should we add some margin..?\n",
    "    return [xmin, ymin, xmax-xmin, ymax-ymin]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bb_from_proj(K, R, t, U, img_width, img_height):\n",
    "    u = K @ (R @ U + t)\n",
    "    u /= u[np.newaxis,2,:]\n",
    "\n",
    "    xmin = int(np.min(u[0,:]))\n",
    "    xmax = int(np.max(u[0,:]))\n",
    "    ymin = int(np.min(u[1,:]))\n",
    "    ymax = int(np.max(u[1,:]))\n",
    "\n",
    "    xmin, xmax = np.clip([xmin, xmax], 0, img_width-1)\n",
    "    ymin, ymax = np.clip([ymin, ymax], 0, img_height-1)\n",
    "\n",
    "#     TODO: Should we add some margin..?\n",
    "    return [xmin, ymin, xmax-xmin, ymax-ymin]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NEW_DATA_PATH = '/home/lucas/datasets/pose-data/sixd/occluded-linemod-augmented4'\n",
    "# OLD_DATA_PATH = '/home/lucas/datasets/pose-data'\n",
    "# OLD_MODELS_PATH = '/home/lucas/datasets/pose-data/ply-models-ascii'\n",
    "OLD_SIXD_LINEMOD_PATH = '/home/lucas/datasets/pose-data/sixd/bop-unzipped/hinterstoisser'\n",
    "# VTX_FRACTION_FOR_PROJ_BB = 0.25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What objects to consider?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Consider only objects for which occluded images exist already (without augmentation)\n",
    "# considered_objs = sorted(set(meta['sequences']['ape']['objects_annotated_in_sequence']) - {'benchviseblue'})\n",
    "\n",
    "# Consider all objects present in test sequence\n",
    "considered_objs = sorted(set(meta['sequences']['benchviseblue']['objects_annotated_in_sequence']) - {'benchviseblue'})\n",
    "\n",
    "# Exclude benchviseblue (not occluded in test sequence)\n",
    "considered_objs = sorted(set(considered_objs) - {'benchviseblue'})\n",
    "\n",
    "already_considered_objs = considered_objs\n",
    "\n",
    "all_objs = set(meta['objects'])\n",
    "# Consider all objects\n",
    "considered_objs = sorted(all_objs)\n",
    "\n",
    "# Consider all objects except the ones already considered\n",
    "#considered_objs = sorted(all_objs - set(already_considered_objs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Camera info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cam_yaml = {}\n",
    "cam_yaml['depth_scale'] = 1.0 # mm -> mm\n",
    "cam_yaml['width'] = 640\n",
    "cam_yaml['height'] = 480\n",
    "cam_yaml['fx'] = meta['camera_calibration']['f_x']\n",
    "cam_yaml['fy'] = meta['camera_calibration']['f_y']\n",
    "cam_yaml['cx'] = meta['camera_calibration']['p_x']\n",
    "cam_yaml['cy'] = meta['camera_calibration']['p_y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"Standard\" calibration be used for synthetic rendering\n",
    "# Calibration should also be store for each frame.\n",
    "os.makedirs(NEW_DATA_PATH, exist_ok=True)\n",
    "inout.save_yaml(os.path.join(NEW_DATA_PATH, 'camera.yml'), cam_yaml)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read models to memory, convert m -> mm, and store new PLY files. Find model info and store as YAML."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "occl_instead_of_sixd_hinter = False\n",
    "\n",
    "if occl_instead_of_sixd_hinter:\n",
    "    depth_rescale_to_mm = 1e3\n",
    "\n",
    "    models = {}\n",
    "    model_yaml = {}\n",
    "    os.makedirs(os.path.join(NEW_DATA_PATH, 'models'), exist_ok=True)\n",
    "    for obj in considered_objs:\n",
    "        bounds = meta['objects'][obj]['bounds']\n",
    "\n",
    "        # SIXD Hinterstoisser\n",
    "        obj_id = model_conversion_meta[obj]['idx_sixd']\n",
    "        models[obj] = inout.load_ply(os.path.join(OLD_SIXD_LINEMOD_PATH, 'models', 'obj_{:02}.ply'.format(obj_id)))\n",
    "\n",
    "        inout.save_ply(\n",
    "            os.path.join(NEW_DATA_PATH, 'models', 'obj_{:02}.ply'.format(obj_id)),\n",
    "            models[obj]['pts'],\n",
    "            pts_colors = models[obj]['colors'],\n",
    "            pts_normals = models[obj]['normals'],\n",
    "            faces = models[obj]['faces'],\n",
    "        )\n",
    "    #     shutil.copyfile(\n",
    "    #         os.path.join(OLD_MODELS_PATH, '{:03}.ply'.format(obj_id)),\n",
    "    #         os.path.join(NEW_DATA_PATH, 'models', 'obj_{:02}.ply'.format(obj_id)),\n",
    "    #     )\n",
    "        model_yaml[obj_id] = {\n",
    "    #         TODO: maximal distance between vertices?\n",
    "    #         distance_matrix = squareform(pdist(model['pts'], metric='euclidean'))\n",
    "    #         'diameter': None,\n",
    "    #         m -> mm\n",
    "            'min_x': depth_rescale_to_mm*(bounds['x'][0]),\n",
    "            'min_y': depth_rescale_to_mm*(bounds['y'][0]),\n",
    "            'min_z': depth_rescale_to_mm*(bounds['z'][0]),\n",
    "    #         Keypoints to be produced later by dedicated script:\n",
    "    #         'kp_x': ,\n",
    "    #         'kp_y': ,\n",
    "    #         'kp_z': ,\n",
    "            'size_x': depth_rescale_to_mm*(bounds['x'][1] - bounds['x'][0]),\n",
    "            'size_y': depth_rescale_to_mm*(bounds['y'][1] - bounds['y'][0]),\n",
    "            'size_z': depth_rescale_to_mm*(bounds['z'][1] - bounds['z'][0]),\n",
    "        }\n",
    "    inout.save_yaml(os.path.join(NEW_DATA_PATH, 'models', 'models_info.yml'), model_yaml)\n",
    "else:\n",
    "    old_model_yaml = inout.load_yaml(os.path.join(OLD_SIXD_LINEMOD_PATH, 'models', 'models_info.yml'))\n",
    "    models = {}\n",
    "    model_yaml = {}\n",
    "    os.makedirs(os.path.join(NEW_DATA_PATH, 'models'), exist_ok=True)\n",
    "    for obj in considered_objs:\n",
    "        obj_id = model_conversion_meta[obj]['idx_sixd']\n",
    "        shutil.copyfile(\n",
    "            os.path.join(OLD_SIXD_LINEMOD_PATH, 'models', 'obj_{:02}.ply'.format(obj_id)),\n",
    "            os.path.join(NEW_DATA_PATH, 'models', 'obj_{:02}.ply'.format(obj_id)),\n",
    "        )\n",
    "        models[obj_id] = inout.load_ply(os.path.join(OLD_SIXD_LINEMOD_PATH, 'models', 'obj_{:02}.ply'.format(obj_id)))\n",
    "        model_yaml[obj_id] = old_model_yaml[obj_id]\n",
    "\n",
    "    inout.save_yaml(os.path.join(NEW_DATA_PATH, 'models', 'models_info.yml'), model_yaml)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Process one frame, move data to new paths, and return YAML annotation contents\n",
    "\"\"\"\n",
    "def process_frame(\n",
    "        old_paths,\n",
    "        new_paths,\n",
    "        seq_path,\n",
    "        frame_idx,\n",
    "    ):\n",
    "\n",
    "    shutil.copyfile(old_paths['img_path'], new_paths['img_path'])\n",
    "    shutil.copyfile(old_paths['depth_path'], new_paths['depth_path'])\n",
    "    shutil.copyfile(old_paths['corrmap_path'], new_paths['corrmap_path'])\n",
    "\n",
    "    objclass_seg = np.array(Image.open(old_paths['seg_path']))\n",
    "\n",
    "#     Initialize with zeros (background). To be filled when iterating over instances.\n",
    "    instance_seg = np.zeros((cam_yaml['height'], cam_yaml['width']), dtype=np.uint8)\n",
    "\n",
    "    info_yaml_curr = {\n",
    "        'cam_K': np.array([\n",
    "            [cam_yaml['fx'],             0.0,    cam_yaml['cx']],\n",
    "            [0.0,             cam_yaml['fy'],    cam_yaml['cy']],\n",
    "            [0.0,                        0.0,               1.0],\n",
    "        ]),\n",
    "        'depth_scale': cam_yaml['depth_scale'],\n",
    "    }\n",
    "    gt_yaml_curr = []\n",
    "    instance_id = 1\n",
    "    for obj, pose_path in old_paths['pose_paths'].items():\n",
    "        obj_id_occl = meta['objects'][obj]['mesh_id']\n",
    "        assert obj_id_occl == model_conversion_meta[obj]['idx_occl']\n",
    "        obj_id_sixd = model_conversion_meta[obj]['idx_sixd']\n",
    "\n",
    "        model = models[obj] if occl_instead_of_sixd_hinter else models[obj_id_sixd]\n",
    "\n",
    "#         Add current object to instance segmentation map\n",
    "        instance_seg[objclass_seg == obj_id_occl] = instance_id\n",
    "\n",
    "        pose = parse_pose(pose_path)\n",
    "        pose['t'] *= 1e3 # m -> mm\n",
    "\n",
    "#         obj_bb = seg2bb(instance_seg, instance_id)\n",
    "#         if obj_bb is None:\n",
    "#             raise Exception('Object {} missing in seq {}, frame {}'.format(obj, seq, frame_idx))\n",
    "        obj_bb = bb_from_proj(info_yaml_curr['cam_K'], pose['R'], pose['t'], model['pts'].T, cam_yaml['width'], cam_yaml['height'])\n",
    "\n",
    "        gt_yaml_curr.append({\n",
    "            'cam_R_m2c': pose['R'] @ model_conversion_meta[obj]['R_occl2sixd'].T,\n",
    "            'cam_t_m2c': pose['t'],\n",
    "            'obj_bb': obj_bb,\n",
    "            'obj_id': obj_id_sixd,\n",
    "            'px_count_visib': seg2pixelcount(instance_seg, instance_id),\n",
    "        })\n",
    "        instance_id += 1\n",
    "\n",
    "#     Save instance seg to file\n",
    "    instance_seg = Image.fromarray(instance_seg)\n",
    "    instance_seg.save(new_paths['seg_path'])\n",
    "\n",
    "    return info_yaml_curr, gt_yaml_curr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_old_paths_aug(seq, frame_idx, considered_objs=None):\n",
    "    return {\n",
    "        'img_path': os.path.join(local_conf['object_centric_data_aug_path'], 'augmented-images', seq, 'rgb', 'augmented_{}.jpg'.format(frame_idx)),\n",
    "        'seg_path': os.path.join(local_conf['object_centric_data_aug_path'], 'augmented-images', seq, 'seg', 'augmented_{}.png'.format(frame_idx)),\n",
    "        'depth_path': os.path.join(local_conf['object_centric_data_aug_path'], 'augmented-images', seq, 'kinect-depth', 'augmented_{:05}.png'.format(frame_idx)),\n",
    "        'corrmap_path': os.path.join(local_conf['object_centric_data_aug_path'], 'augmented-images', seq, 'coords', 'augmented_{:05}.png'.format(frame_idx)),\n",
    "        'pose_paths': get_pose_paths(seq, frame_idx, os.path.join(local_conf['object_centric_data_aug_path'], 'infos-augmented'), considered_objs=considered_objs),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_old_paths_lm_occl(seq, frame_idx, considered_objs=None):\n",
    "    return {\n",
    "        'img_path': os.path.join(local_conf['linemod_path'], 'data', seq, 'data', 'color{}.jpg'.format(frame_idx)),\n",
    "        'seg_path': os.path.join(local_conf['rendered_path'], seq, 'seg', 'seg_{:05}.png'.format(frame_idx)),\n",
    "        'depth_path': os.path.join(local_conf['linemod_depth_path'], seq, 'depth', 'depth_{:05}.png'.format(frame_idx)),\n",
    "        'corrmap_path': os.path.join(local_conf['rendered_path'], seq, 'coords', 'coords_{:05}.png'.format(frame_idx)),\n",
    "        'pose_paths': get_pose_paths(seq, frame_idx, local_conf['pose_annos_path'], considered_objs=considered_objs),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_old_paths_synthetic(seq, frame_idx, considered_objs=None):\n",
    "    return {\n",
    "        'img_path': os.path.join(local_conf['synthetic_path'], 'rendered', seq, 'rgb_with_bg', 'rgb_{:05}.jpg'.format(frame_idx)),\n",
    "        'seg_path': os.path.join(local_conf['synthetic_path'], 'rendered', seq, 'seg', 'seg_{:05}.png'.format(frame_idx)),\n",
    "        'depth_path': os.path.join(local_conf['synthetic_path'], 'rendered', seq, 'depth', 'depth_{:05}.png'.format(frame_idx)),\n",
    "        'corrmap_path': os.path.join(local_conf['synthetic_path'], 'rendered', seq, 'coords', 'coords_{:05}.png'.format(frame_idx)),\n",
    "        'pose_paths': get_pose_paths(seq, frame_idx, os.path.join(local_conf['synthetic_path'], 'poses'), considered_objs=considered_objs),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_new_paths(seq_path, frame_idx):\n",
    "    return {\n",
    "        'img_path': os.path.join(seq_path, 'rgb', '{:06}.png'.format(frame_idx)),\n",
    "        'seg_path': os.path.join(seq_path, 'instance_seg', '{:06}.png'.format(frame_idx)),\n",
    "        'depth_path': os.path.join(seq_path, 'depth', '{:06}.png'.format(frame_idx)),\n",
    "        'corrmap_path': os.path.join(seq_path, 'obj', '{:06}.png'.format(frame_idx)),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dirs(seq_path):\n",
    "    os.makedirs(seq_path, exist_ok=True)\n",
    "    os.makedirs(os.path.join(seq_path, 'rgb'), exist_ok=True)\n",
    "    os.makedirs(os.path.join(seq_path, 'instance_seg'), exist_ok=True)\n",
    "    os.makedirs(os.path.join(seq_path, 'depth'), exist_ok=True)\n",
    "    os.makedirs(os.path.join(seq_path, 'obj'), exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training set - augmented sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # TESTING\n",
    "# # TESTING\n",
    "# # TESTING\n",
    "# # TESTING\n",
    "# # TESTING\n",
    "# # TESTING\n",
    "# # TESTING\n",
    "# # TESTING\n",
    "# # TESTING\n",
    "# # TESTING\n",
    "# # Set of sequences coincides with set of objects\n",
    "# seqs = considered_objs\n",
    "# for seq in seqs:\n",
    "# #     Discard sequence if \"occluded objects\" not present\n",
    "#     if not len(set(meta['sequences'][seq]['objects_annotated_in_sequence']) & set(seqs)) > 0:\n",
    "#         continue\n",
    "\n",
    "#     seq_path = os.path.join(NEW_DATA_PATH, 'train_aug', seq)\n",
    "#     make_dirs(seq_path)\n",
    "\n",
    "#     info_yaml = {}\n",
    "#     gt_yaml = {}\n",
    "\n",
    "#     indices = [0]\n",
    "# #     indices = range(len(os.listdir(os.path.join(local_conf['object_centric_data_aug_path'], 'augmented-images', seq, 'rgb'))))\n",
    "\n",
    "#     print(\"Seq: {}, Frames to process: {}.\".format(seq, len(indices)))\n",
    "\n",
    "#     for frame_idx in indices:\n",
    "\n",
    "#         info_yaml[frame_idx], gt_yaml[frame_idx] = process_frame(\n",
    "#             get_old_paths_aug(seq, frame_idx, considered_objs),\n",
    "#             get_new_paths(seq_path, frame_idx),\n",
    "#             seq_path,\n",
    "#             frame_idx,\n",
    "#         )\n",
    "\n",
    "# #     inout.save_info(os.path.join(seq_path, 'info.yml'), info_yaml)\n",
    "# #     inout.save_gt(os.path.join(seq_path, 'gt.yml'), gt_yaml)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set of sequences coincides with set of objects\n",
    "seqs = considered_objs\n",
    "for seq in seqs:\n",
    "#     Discard sequence if \"occluded objects\" not present\n",
    "    if not len(set(meta['sequences'][seq]['objects_annotated_in_sequence']) & set(seqs)) > 0:\n",
    "        continue\n",
    "\n",
    "    seq_path = os.path.join(NEW_DATA_PATH, 'train_aug', seq)\n",
    "    make_dirs(seq_path)\n",
    "\n",
    "    info_yaml = {}\n",
    "    gt_yaml = {}\n",
    "\n",
    "    indices = range(len(os.listdir(os.path.join(local_conf['object_centric_data_aug_path'], 'augmented-images', seq, 'rgb'))))\n",
    "\n",
    "    print(\"Seq: {}, Frames to process: {}.\".format(seq, len(indices)))\n",
    "\n",
    "    for frame_idx in indices:\n",
    "\n",
    "        info_yaml[frame_idx], gt_yaml[frame_idx] = process_frame(\n",
    "            get_old_paths_aug(seq, frame_idx, considered_objs),\n",
    "            get_new_paths(seq_path, frame_idx),\n",
    "            seq_path,\n",
    "            frame_idx,\n",
    "        )\n",
    "\n",
    "    inout.save_info(os.path.join(seq_path, 'info.yml'), info_yaml)\n",
    "    inout.save_gt(os.path.join(seq_path, 'gt.yml'), gt_yaml)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training set - unoccluded LINEMOD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for obj in considered_objs:\n",
    "    seq = obj\n",
    "    seq_path = os.path.join(NEW_DATA_PATH, 'train_unoccl', seq)\n",
    "    make_dirs(seq_path)\n",
    "\n",
    "    info_yaml = {}\n",
    "    gt_yaml = {}\n",
    "\n",
    "    indices = range(meta['sequences'][seq]['sequence_length'])\n",
    "\n",
    "    print(\"Seq: {}, Frames to process: {}.\".format(seq, len(indices)))\n",
    "\n",
    "    for frame_idx in indices:\n",
    "        info_yaml[frame_idx], gt_yaml[frame_idx] = process_frame(\n",
    "            get_old_paths_lm_occl(seq, frame_idx, [obj]),\n",
    "            get_new_paths(seq_path, frame_idx),\n",
    "            seq_path,\n",
    "            frame_idx,\n",
    "        )\n",
    "\n",
    "    inout.save_info(os.path.join(seq_path, 'info.yml'), info_yaml)\n",
    "    inout.save_gt(os.path.join(seq_path, 'gt.yml'), gt_yaml)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training set - occluded ape sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for seq in ['ape']:\n",
    "    seq_path = os.path.join(NEW_DATA_PATH, 'train_occl', seq)\n",
    "    make_dirs(seq_path)\n",
    "\n",
    "    info_yaml = {}\n",
    "    gt_yaml = {}\n",
    "\n",
    "    indices = range(meta['sequences'][seq]['sequence_length'])\n",
    "\n",
    "    print(\"Seq: {}, Frames to process: {}.\".format(seq, len(indices)))\n",
    "\n",
    "    for frame_idx in indices:\n",
    "        info_yaml[frame_idx], gt_yaml[frame_idx] = process_frame(\n",
    "            get_old_paths_lm_occl(seq, frame_idx, considered_objs),\n",
    "            get_new_paths(seq_path, frame_idx),\n",
    "            seq_path,\n",
    "            frame_idx,\n",
    "        )\n",
    "\n",
    "    inout.save_info(os.path.join(seq_path, 'info.yml'), info_yaml)\n",
    "    inout.save_gt(os.path.join(seq_path, 'gt.yml'), gt_yaml)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training set - synthetic images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for seq in ['seq']:\n",
    "    seq_path = os.path.join(NEW_DATA_PATH, 'train_synthetic', seq)\n",
    "    make_dirs(seq_path)\n",
    "\n",
    "    info_yaml = {}\n",
    "    gt_yaml = {}\n",
    "\n",
    "    indices = range(40000)\n",
    "\n",
    "    print(\"Seq: {}, Frames to process: {}.\".format(seq, len(indices)))\n",
    "\n",
    "    for frame_idx in indices:\n",
    "        info_yaml[frame_idx], gt_yaml[frame_idx] = process_frame(\n",
    "            get_old_paths_synthetic(seq, frame_idx, considered_objs),\n",
    "            get_new_paths(seq_path, frame_idx),\n",
    "            seq_path,\n",
    "            frame_idx,\n",
    "        )\n",
    "\n",
    "    inout.save_info(os.path.join(seq_path, 'info.yml'), info_yaml)\n",
    "    inout.save_gt(os.path.join(seq_path, 'gt.yml'), gt_yaml)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test set - occluded benchviseblue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for seq in ['benchviseblue']:\n",
    "    seq_path = os.path.join(NEW_DATA_PATH, 'test_occl', seq)\n",
    "    make_dirs(seq_path)\n",
    "\n",
    "    info_yaml = {}\n",
    "    gt_yaml = {}\n",
    "\n",
    "    indices = indices = range(meta['sequences'][seq]['sequence_length'])\n",
    "\n",
    "    print(\"Seq: {}, Frames to process: {}.\".format(seq, len(indices)))\n",
    "\n",
    "    for frame_idx in indices:\n",
    "        info_yaml[frame_idx], gt_yaml[frame_idx] = process_frame(\n",
    "            get_old_paths_lm_occl(seq, frame_idx, considered_objs),\n",
    "            get_new_paths(seq_path, frame_idx),\n",
    "            seq_path,\n",
    "            frame_idx,\n",
    "        )\n",
    "\n",
    "    inout.save_info(os.path.join(seq_path, 'info.yml'), info_yaml)\n",
    "    inout.save_gt(os.path.join(seq_path, 'gt.yml'), gt_yaml)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
